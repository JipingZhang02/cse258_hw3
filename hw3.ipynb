{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TQDM_ON = True\n",
    "if TQDM_ON:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN_DATA_GZIP_PATH = \"./train.json.gz\"\n",
    "TRAINSET_DEFAULT_SAVE_PATH = \"./train.json\"\n",
    "PAIR_HOUR_VALIDSET_FILE_DEFAULT_PATH = \"./pairs_Hours_validset.csv\"\n",
    "PAIR_PLAYED_VALIDSET_FILE_DEFAULT_PATH = \"./pairs_Played_validset.csv\"\n",
    "PRED_HOUR_VALIDSET_FILE_DEFAULT_PATH = \"./predictions_Hours_validset.csv\"\n",
    "PRED_PLAYED_VALIDSET_FILE_DEFAULT_PATH = \"./predictions_Played_validset.csv\"\n",
    "PAIR_HOUR_TESTSET_FILE_DEFAULT_PATH = \"./pairs_Hours.csv\"\n",
    "PAIR_PLAYED_TESTSET_FILE_DEFAULT_PATH = \"./pairs_Played.csv\"\n",
    "PRED_HOUR_TESTSET_FILE_DEFAULT_PATH = \"./predictions_Hours.csv\"\n",
    "PRED_PLAYED_TESTSET_FILE_DEFAULT_PATH = \"./predictions_Played.csv\"\n",
    "q5_output_path=\"HWpredictions_Played.csv\"\n",
    "q8_output_path=\"HWpredictions_Hours.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt',encoding=\"utf-8\")\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_json_file(path:str):\n",
    "    with open(path,encoding=\"utf-8\") as fin:\n",
    "        lines = fin.readlines()\n",
    "    for l in lines:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}\n",
    "# Some data structures that will be useful\n",
    "allHours = []\n",
    "for l in readJSON(\"./train.json.gz\"):\n",
    "    allHours.append(l)\n",
    "hoursTrain = allHours[:165000]\n",
    "hoursValid = allHours[165000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record wich games every user has played\n",
    "games_per_user = defaultdict(set)\n",
    "for uid,game_id,_ in allHours:\n",
    "    games_per_user[uid].add(game_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games = set()\n",
    "for _,game_id,_ in hoursTrain:\n",
    "    all_games.add(game_id)\n",
    "all_games = list(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set_with_neg_sample = list()\n",
    "\n",
    "for uid,game_id,_ in hoursValid:\n",
    "    games_this_user_played = games_per_user[uid]\n",
    "    rand_sample_game = all_games[random.randint(0,len(all_games)-1)]\n",
    "    while rand_sample_game in games_this_user_played:\n",
    "        rand_sample_game = all_games[random.randint(0,len(all_games)-1)]\n",
    "    valid_set_with_neg_sample.append((uid,game_id,1))\n",
    "    valid_set_with_neg_sample.append((uid,rand_sample_game,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_file_for_eval(dataset,path:str):\n",
    "    with open(path,\"w+\",encoding=\"utf-8\") as fout:\n",
    "        fout.write(\"userID,gameID,prediction\\n\")\n",
    "        for datum in dataset:\n",
    "            uid = datum[0]\n",
    "            game_id = datum[1]\n",
    "            fout.write(f\"{uid},{game_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_set(train_set,path:str):\n",
    "    assert type(train_set)==list\n",
    "    t0 = train_set[0]\n",
    "    assert type(t0)==tuple\n",
    "    assert type(t0[2])==dict\n",
    "    with open(path,\"w+\",encoding=\"utf-8\") as fout:\n",
    "        for datum in train_set:\n",
    "            fout.write(str(datum[2])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_train_set(hoursTrain,TRAINSET_DEFAULT_SAVE_PATH)\n",
    "save_as_file_for_eval(valid_set_with_neg_sample,PAIR_PLAYED_VALIDSET_FILE_DEFAULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline_model(*,train_file_path:str=TRAINSET_DEFAULT_SAVE_PATH,\n",
    "                       pair_hour_file_path:str=PAIR_HOUR_VALIDSET_FILE_DEFAULT_PATH,\n",
    "                       pair_played_file_path:str=PAIR_PLAYED_VALIDSET_FILE_DEFAULT_PATH,\n",
    "                       prediction_hour_output_path:str=PRED_HOUR_VALIDSET_FILE_DEFAULT_PATH,\n",
    "                       prediction_played_output_path:str=PRED_PLAYED_VALIDSET_FILE_DEFAULT_PATH):\n",
    "    allHours = []\n",
    "    userHours = defaultdict(list)\n",
    "\n",
    "    for user, game, d in read_raw_json_file(train_file_path):\n",
    "        h = d[\"hours_transformed\"]\n",
    "        allHours.append(h)\n",
    "        userHours[user].append(h)\n",
    "\n",
    "    globalAverage = sum(allHours) / len(allHours)\n",
    "    userAverage = {}\n",
    "    for u in userHours:\n",
    "        userAverage[u] = sum(userHours[u]) / len(userHours[u])\n",
    "\n",
    "    predictions = open(prediction_hour_output_path, \"w\")\n",
    "    for l in open(pair_hour_file_path):\n",
    "        if l.startswith(\"userID\"):\n",
    "            # header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u, g = l.strip().split(\",\")\n",
    "        if u in userAverage:\n",
    "            predictions.write(u + \",\" + g + \",\" + str(userAverage[u]) + \"\\n\")\n",
    "        else:\n",
    "            predictions.write(u + \",\" + g + \",\" + str(globalAverage) + \"\\n\")\n",
    "\n",
    "    predictions.close()\n",
    "\n",
    "    ### Would-play baseline: just rank which games are popular and which are not, and return '1' if a game is among the top-ranked\n",
    "\n",
    "    gameCount = defaultdict(int)\n",
    "    totalPlayed = 0\n",
    "\n",
    "    for user, game, _ in read_raw_json_file(train_file_path):\n",
    "        gameCount[game] += 1\n",
    "        totalPlayed += 1\n",
    "\n",
    "    mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > totalPlayed / 2:\n",
    "            break\n",
    "\n",
    "    predictions = open(prediction_played_output_path, \"w\")\n",
    "    for l in open(pair_played_file_path):\n",
    "        if l.startswith(\"userID\"):\n",
    "            # header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u, g = l.strip().split(\",\")\n",
    "        if g in return1:\n",
    "            predictions.write(u + \",\" + g + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + \",\" + g + \",0\\n\")\n",
    "\n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set_with_neg_sample_map = {(u,g):res for u,g,res in valid_set_with_neg_sample}\n",
    "def calculate_pred_play_accu(pred_played_file_path:str=PRED_PLAYED_VALIDSET_FILE_DEFAULT_PATH):\n",
    "    correct_cnt,total_cnt=0,0\n",
    "    with open(pred_played_file_path) as fin:\n",
    "        lines = fin.readlines()\n",
    "        assert lines[0].startswith(\"userID,gameID,prediction\"),f\"csv file {pred_played_file_path} has wrong header\"\n",
    "        for line in lines[1:]:\n",
    "            uid,gid,pred_str = line.strip().split(\",\")\n",
    "            total_cnt+=1\n",
    "            correct_cnt+=int(pred_str)==valid_set_with_neg_sample_map[(uid,gid)]\n",
    "    assert total_cnt==len(valid_set_with_neg_sample)\n",
    "    return correct_cnt/total_cnt\n",
    "\n",
    "accu1 = calculate_pred_play_accu()\n",
    "answers['Q1'] = accu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6805680568056806"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred_play_model2(threshold:float,\n",
    "                       *,train_file_path:str=TRAINSET_DEFAULT_SAVE_PATH,\n",
    "                       pair_played_file_path:str=PAIR_PLAYED_VALIDSET_FILE_DEFAULT_PATH,\n",
    "                       prediction_played_output_path:str=PRED_PLAYED_VALIDSET_FILE_DEFAULT_PATH):\n",
    "    \n",
    "    gameCount = defaultdict(int)\n",
    "    totalPlayed = 0\n",
    "\n",
    "    for user, game, _ in read_raw_json_file(train_file_path):\n",
    "        gameCount[game] += 1\n",
    "        totalPlayed += 1\n",
    "\n",
    "    mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > totalPlayed * threshold:\n",
    "            break\n",
    "\n",
    "    predictions = open(prediction_played_output_path, \"w\")\n",
    "    for l in open(pair_played_file_path):\n",
    "        if l.startswith(\"userID\"):\n",
    "            # header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u, g = l.strip().split(\",\")\n",
    "        if g in return1:\n",
    "            predictions.write(u + \",\" + g + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + \",\" + g + \",0\\n\")\n",
    "\n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_max(l,r,iter_times,each_split,cal_accu_func):\n",
    "    iter_range = range(iter_times)\n",
    "    if TQDM_ON:\n",
    "        iter_range = tqdm(iter_range)\n",
    "    for i in iter_range:\n",
    "        thsld_with_accu = list()\n",
    "        split_i_range = range(1,each_split)\n",
    "        each_split_size = (r-l)/each_split\n",
    "        if TQDM_ON:\n",
    "            split_i_range = tqdm(split_i_range)\n",
    "        for s_i in split_i_range:\n",
    "            x_s_i = l+each_split_size*s_i\n",
    "            # my_pred_play_model2(x_s_i)\n",
    "            # accu_this = calculate_pred_play_accu()\n",
    "            accu_this = cal_accu_func(x_s_i)\n",
    "            thsld_with_accu.append((x_s_i,accu_this))\n",
    "            thsld_with_accu.sort(key=lambda tup:tup[1],reverse=True)\n",
    "            ths_max_accu = thsld_with_accu[0][0]\n",
    "            max_accu = thsld_with_accu[0][1]\n",
    "            l,r = ths_max_accu-each_split_size,ths_max_accu+each_split_size\n",
    "    return (ths_max_accu,max_accu)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:31<00:00,  6.27s/it]\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.36s/it]\n",
      "100%|██████████| 5/5 [00:27<00:00,  5.54s/it]\n",
      "100%|██████████| 5/5 [00:27<00:00,  5.52s/it]\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.37s/it]\n",
      "100%|██████████| 5/5 [02:20<00:00, 28.08s/it]\n"
     ]
    }
   ],
   "source": [
    "def cal_accu_func2(thsld):\n",
    "    my_pred_play_model2(thsld)\n",
    "    return calculate_pred_play_accu()\n",
    "\n",
    "ans2 = search_max(0.0,1.0,5,6,cal_accu_func2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l,r=0.0,1.0\n",
    "# iter_times = 5\n",
    "# each_split = 6\n",
    "# iter_range = range(iter_times)\n",
    "# if TQDM_ON:\n",
    "#     iter_range = tqdm(iter_range)\n",
    "# for i in iter_range:\n",
    "#     thsld_with_accu = list()\n",
    "#     split_i_range = range(1,each_split)\n",
    "#     each_split_size = (r-l)/each_split\n",
    "#     if TQDM_ON:\n",
    "#         split_i_range = tqdm(split_i_range)\n",
    "#     for s_i in split_i_range:\n",
    "#         threshold = l+each_split_size*s_i\n",
    "#         my_pred_play_model2(threshold)\n",
    "#         accu_this = calculate_pred_play_accu()\n",
    "#         thsld_with_accu.append((threshold,accu_this))\n",
    "#         thsld_with_accu.sort(key=lambda tup:tup[1],reverse=True)\n",
    "#         ths_max_accu = thsld_with_accu[0][0]\n",
    "#         max_accu = thsld_with_accu[0][1]\n",
    "#         l,r = ths_max_accu-each_split_size,ths_max_accu+each_split_size\n",
    "# answers[\"Q2\"]=[ths_max_accu,max_accu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q2\"]=list(ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(set1,set2):\n",
    "    return len(set1.intersection(set2))/len(set1.union(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pred_play_model3(threshold:float,\n",
    "                       *,train_file_path:str=TRAINSET_DEFAULT_SAVE_PATH,\n",
    "                       pair_played_file_path:str=PAIR_PLAYED_VALIDSET_FILE_DEFAULT_PATH,\n",
    "                       prediction_played_output_path:str=PRED_PLAYED_VALIDSET_FILE_DEFAULT_PATH):\n",
    "\n",
    "    user_per_game = defaultdict(set)\n",
    "    game_per_user = defaultdict(set)\n",
    "\n",
    "    for user, game, _ in read_raw_json_file(train_file_path):\n",
    "        user_per_game[game].add(user)\n",
    "        game_per_user[user].add(game)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = open(prediction_played_output_path, \"w\")\n",
    "    for l in open(pair_played_file_path):\n",
    "        if l.startswith(\"userID\"):\n",
    "            # header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u, g = l.strip().split(\",\")\n",
    "        users_played_this_game = user_per_game[g]\n",
    "        pred_res = 0\n",
    "        for g2 in game_per_user[u]:\n",
    "            if jaccard_sim(user_per_game[g2],users_played_this_game)>=threshold:\n",
    "                pred_res=1\n",
    "                break\n",
    "        predictions.write(f\"{u},{g},{pred_res}\\n\")\n",
    "\n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:24<00:00, 16.94s/it]\n",
      "100%|██████████| 5/5 [01:11<00:00, 14.28s/it]\n",
      "100%|██████████| 5/5 [01:23<00:00, 16.76s/it]\n",
      "100%|██████████| 5/5 [01:38<00:00, 19.74s/it]\n",
      "100%|██████████| 5/5 [01:14<00:00, 14.89s/it]\n",
      "100%|██████████| 5/5 [01:10<00:00, 14.06s/it]\n",
      "100%|██████████| 6/6 [08:03<00:00, 80.56s/it]\n"
     ]
    }
   ],
   "source": [
    "def cal_accu_func3(thsld):\n",
    "    my_pred_play_model3(thsld)\n",
    "    return calculate_pred_play_accu()\n",
    "\n",
    "ans3 = search_max(0.0,1.0,6,6,cal_accu_func3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1673525377229081, 0.5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q3\"]=ans3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165000/165000 [02:47<00:00, 985.41it/s] \n"
     ]
    }
   ],
   "source": [
    "gameCount = defaultdict(int)\n",
    "totalPlayed = 0\n",
    "\n",
    "user_per_game = defaultdict(set)\n",
    "game_per_user = defaultdict(set)\n",
    "\n",
    "for user, game, _ in read_raw_json_file(TRAINSET_DEFAULT_SAVE_PATH):\n",
    "    gameCount[game] += 1\n",
    "    totalPlayed += 1\n",
    "    user_per_game[game].add(user)\n",
    "    game_per_user[user].add(game)\n",
    "\n",
    "mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "popular_games = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    popular_games.add(i)\n",
    "    if count > totalPlayed * answers[\"Q2\"][0]:\n",
    "        break\n",
    "\n",
    "\n",
    "def getX4(uid,game_id):\n",
    "    users_played_this_game = user_per_game[game_id]\n",
    "    max_jaccard_sim = 0.0\n",
    "    game_user_played = game_per_user[uid]\n",
    "    if len(game_user_played)>1:\n",
    "        max_jaccard_sim = max(jaccard_sim(user_per_game[g2],users_played_this_game) for g2 in game_user_played if g2!=g)\n",
    "    is_this_game_pop = game_id in popular_games\n",
    "    return [float(is_this_game_pop),max_jaccard_sim]\n",
    "\n",
    "\n",
    "X4 = list()\n",
    "Y4 = list()\n",
    "for u,g,_d in (hoursTrain if not TQDM_ON else tqdm(hoursTrain)):\n",
    "    rand_sample_game = all_games[random.randint(0,len(all_games)-1)]\n",
    "    while rand_sample_game in games_this_user_played:\n",
    "        rand_sample_game = all_games[random.randint(0,len(all_games)-1)]\n",
    "    x_pos = getX4(u,g)\n",
    "    X4.append(x_pos)\n",
    "    Y4.append(1.0)\n",
    "    x_neg = getX4(u,rand_sample_game)\n",
    "    X4.append(x_neg)\n",
    "    Y4.append(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4 = numpy.array(X4)\n",
    "Y4 = numpy.array(Y4)\n",
    "logistic_reg = linear_model.LogisticRegression()\n",
    "logistic_reg.fit(X4,Y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = list(valid_set_with_neg_sample_map.items())\n",
    "X4_validset = [getX4(u,g) for ((u,g),_) in tmp]\n",
    "Y4_validset_label = [label for (_,label) in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y4_validset_pred = logistic_reg.predict(X4_validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_cnt = 0\n",
    "for y4l,y4p in zip(Y4_validset_label,Y4_validset_pred):\n",
    "    correct_cnt+=int((y4p>=0.5)==(y4l>=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu4 = correct_cnt/len(Y4_validset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q4\"] = accu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': 0.6805680568056806,\n",
       " 'Q2': [0.6893004115226337, 0.7024702470247025],\n",
       " 'Q3': 0.5,\n",
       " 'Q4': 0.7024607382214665}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PAIR_PLAYED_TESTSET_FILE_DEFAULT_PATH) as fin:\n",
    "    lines = fin.readlines()\n",
    "    assert lines[0].startswith(\"userID,gameID,prediction\")\n",
    "    X5 = list()\n",
    "    user_game_tuples = list()\n",
    "    for line in lines[1:]:\n",
    "        u,g=tuple(line.strip().split(\",\"))\n",
    "        user_game_tuples.append((u,g))\n",
    "        X5.append(getX4(u,g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = numpy.array(X5)\n",
    "Y5_pred = logistic_reg.predict(X5)\n",
    "with open(q5_output_path,\"w+\") as fout:\n",
    "    fout.write(\"userID,gameID,prediction\\n\")\n",
    "    for (u,g),y_pred in zip(user_game_tuples,Y5_pred):\n",
    "        y_pred_int = 1 if y_pred>=0.5 else 0\n",
    "        fout.write(f\"{u},{g},{y_pred_int}\\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = \"I confirm that I have uploaded an assignment submission to gradescope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pred_train_valid_split=0.95 # 5% data used as valid set , 90% as train\n",
    "split_pos = int(time_pred_train_valid_split*len(allHours))\n",
    "time_pred_dataset_all = [(u,g,math.log2(1.0+d['hours'])) for (u,g,d) in allHours]\n",
    "# random.shuffle(time_pred_dataset_all)\n",
    "time_pred_trainset = time_pred_dataset_all[:split_pos]\n",
    "time_pred_validset = time_pred_dataset_all[split_pos:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:02<00:30,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "nTrain = split_pos\n",
    "regularization_lambda = 1.0\n",
    "\n",
    "user_per_game = defaultdict(set)\n",
    "game_per_user = defaultdict(set)\n",
    "ug_time_mapping = dict()\n",
    "\n",
    "for (u,g,transformed_t) in time_pred_trainset:\n",
    "    user_per_game[g].add(u)\n",
    "    game_per_user[u].add(g)\n",
    "    ug_time_mapping[(u,g)]=transformed_t\n",
    "\n",
    "hoursPerUser = {u:sum(ug_time_mapping[(u,g)] for g in game_per_user[u]) for u in game_per_user}\n",
    "hoursPerItem = {g:sum(ug_time_mapping[(u,g)] for u in user_per_game[g]) for g in user_per_game}\n",
    "globalAverage = sum(t for (_u,_g,t) in time_pred_trainset)/len(time_pred_trainset)\n",
    "\n",
    "betaU = {}\n",
    "betaI = {}\n",
    "for u in hoursPerUser:\n",
    "    betaU[u] = hoursPerUser[u]/len(game_per_user[u])-globalAverage\n",
    "\n",
    "for g in hoursPerItem:\n",
    "    betaI[g] = hoursPerItem[g]/len(user_per_game[g])-globalAverage\n",
    "\n",
    "alpha = globalAverage \n",
    "\n",
    "assert len(betaU)==len(game_per_user)\n",
    "assert len(betaI)==len(user_per_game)\n",
    "\n",
    "def predict(u,g):\n",
    "    res = alpha\n",
    "    if u in betaU:\n",
    "        res+=betaU[u]\n",
    "    if g in betaI:\n",
    "        res+=betaI[g]\n",
    "    return res\n",
    "\n",
    "def mse(label,pred):\n",
    "    assert len(label)==len(pred)\n",
    "    return sum((y-ypred)**2 for y,ypred in zip(label,pred))/len(label)\n",
    "\n",
    "def eval_mse():\n",
    "    labels = list()\n",
    "    pred = list()\n",
    "    for u,g,t in time_pred_validset:\n",
    "        labels.append(t)\n",
    "        pred.append(predict(u,g))\n",
    "    return mse(labels,pred)\n",
    "\n",
    "\n",
    "# print(f\"mse before start is {eval_mse()}\")\n",
    "iter_times = 100\n",
    "iter_times_range = range(iter_times)\n",
    "if TQDM_ON:\n",
    "    iter_times_range = tqdm(iter_times_range)\n",
    "mse_valid = 1000000000.0\n",
    "mse_continue_rising = 0\n",
    "for i in iter_times_range:\n",
    "    alpha_sum = 0.0\n",
    "    for (u,g,t) in time_pred_trainset:\n",
    "        alpha_sum+=t-betaU[u]-betaI[g]\n",
    "    alpha_next = alpha_sum/nTrain\n",
    "    alpha=alpha_next\n",
    "\n",
    "    betaU_next = dict()\n",
    "    for u in game_per_user:\n",
    "        games_this_user_played = game_per_user[u]\n",
    "        rating_delta_sum = 0.0\n",
    "        for g in games_this_user_played:\n",
    "            rating_delta_sum+=ug_time_mapping[(u,g)]-alpha-betaI[g]\n",
    "        betaU_next[u] = rating_delta_sum/(len(games_this_user_played)+regularization_lambda)\n",
    "    assert len(betaU)==len(betaU_next)\n",
    "    betaU = betaU_next\n",
    "\n",
    "    betaI_next = dict()\n",
    "    for g in user_per_game:\n",
    "        users_played_this_game = user_per_game[g]\n",
    "        rating_delta_sum = 0.0\n",
    "        for u in users_played_this_game:\n",
    "            rating_delta_sum+=ug_time_mapping[(u,g)]-alpha-betaU[u]\n",
    "        betaI_next[g] = rating_delta_sum/(len(users_played_this_game)+regularization_lambda)\n",
    "    assert len(betaI)==len(betaI_next)\n",
    "    betaI = betaI_next\n",
    "\n",
    "    \n",
    "    mse_this = eval_mse()\n",
    "    if mse_this>mse_valid:\n",
    "        mse_continue_rising+=1\n",
    "        if mse_continue_rising>=2:\n",
    "            break\n",
    "    else:\n",
    "        mse_valid = mse_this\n",
    "        mse_continue_rising =0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q6\"] = eval_mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.020284107204664"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[\"Q6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum betaU = u60898505 (5.823295000744024)\n",
      "Maximum betaI = g17604638 (4.975241175394651)\n",
      "Minimum betaU = u13037838 (-3.001305761201595)\n",
      "Minimum betaI = g84397720 (-3.3500410268554646)\n"
     ]
    }
   ],
   "source": [
    "betaUs = [(betaU[u], u) for u in betaU]\n",
    "betaIs = [(betaI[i], i) for i in betaI]\n",
    "betaUs.sort()\n",
    "betaIs.sort()\n",
    "\n",
    "print(\"Maximum betaU = \" + str(betaUs[-1][1]) + ' (' + str(betaUs[-1][0]) + ')')\n",
    "print(\"Maximum betaI = \" + str(betaIs[-1][1]) + ' (' + str(betaIs[-1][0]) + ')')\n",
    "print(\"Minimum betaU = \" + str(betaUs[0][1]) + ' (' + str(betaUs[0][0]) + ')')\n",
    "print(\"Minimum betaI = \" + str(betaIs[0][1]) + ' (' + str(betaIs[0][0]) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = [betaUs[-1][0], betaUs[0][0], betaIs[-1][0], betaIs[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q8_fit(regularization_lambda):    \n",
    "    betaU = {}\n",
    "    betaI = {}\n",
    "    for u in hoursPerUser:\n",
    "        betaU[u] = hoursPerUser[u]/len(game_per_user[u])-globalAverage\n",
    "\n",
    "    for g in hoursPerItem:\n",
    "        betaI[g] = hoursPerItem[g]/len(user_per_game[g])-globalAverage\n",
    "\n",
    "    alpha = globalAverage \n",
    "\n",
    "    assert len(betaU)==len(game_per_user)\n",
    "    assert len(betaI)==len(user_per_game)\n",
    "\n",
    "    def predict(u,g):\n",
    "        res = alpha\n",
    "        if u in betaU:\n",
    "            res+=betaU[u]\n",
    "        if g in betaI:\n",
    "            res+=betaI[g]\n",
    "        return res\n",
    "\n",
    "    def mse(label,pred):\n",
    "        assert len(label)==len(pred)\n",
    "        return sum((y-ypred)**2 for y,ypred in zip(label,pred))/len(label)\n",
    "\n",
    "    def eval_mse():\n",
    "        labels = list()\n",
    "        pred = list()\n",
    "        for u,g,t in time_pred_validset:\n",
    "            labels.append(t)\n",
    "            pred.append(predict(u,g))\n",
    "        return mse(labels,pred)\n",
    "\n",
    "\n",
    "    # print(f\"mse before start is {eval_mse()}\")\n",
    "    iter_times = 100\n",
    "    iter_times_range = range(iter_times)\n",
    "    if TQDM_ON:\n",
    "        iter_times_range = tqdm(iter_times_range)\n",
    "    mse_valid = 1000000000.0\n",
    "    mse_continue_rising = 0\n",
    "    for i in iter_times_range:\n",
    "        alpha_sum = 0.0\n",
    "        for (u,g,t) in time_pred_trainset:\n",
    "            alpha_sum+=t-betaU[u]-betaI[g]\n",
    "        alpha_next = alpha_sum/nTrain\n",
    "        alpha=alpha_next\n",
    "\n",
    "        betaU_next = dict()\n",
    "        for u in game_per_user:\n",
    "            games_this_user_played = game_per_user[u]\n",
    "            rating_delta_sum = 0.0\n",
    "            for g in games_this_user_played:\n",
    "                rating_delta_sum+=ug_time_mapping[(u,g)]-alpha-betaI[g]\n",
    "            betaU_next[u] = rating_delta_sum/(len(games_this_user_played)+regularization_lambda)\n",
    "        assert len(betaU)==len(betaU_next)\n",
    "        betaU = betaU_next\n",
    "\n",
    "        betaI_next = dict()\n",
    "        for g in user_per_game:\n",
    "            users_played_this_game = user_per_game[g]\n",
    "            rating_delta_sum = 0.0\n",
    "            for u in users_played_this_game:\n",
    "                rating_delta_sum+=ug_time_mapping[(u,g)]-alpha-betaU[u]\n",
    "            betaI_next[g] = rating_delta_sum/(len(users_played_this_game)+regularization_lambda)\n",
    "        assert len(betaI)==len(betaI_next)\n",
    "        betaI = betaI_next\n",
    "\n",
    "        \n",
    "        mse_this = eval_mse()\n",
    "        if mse_this>mse_valid:\n",
    "            mse_continue_rising+=1\n",
    "            if mse_continue_rising>=2:\n",
    "                break\n",
    "        else:\n",
    "            mse_valid = mse_this\n",
    "            mse_continue_rising =0\n",
    "\n",
    "    return alpha,betaU,betaI,eval_mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:41,  2.36it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:39,  2.49it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:41,  2.34it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:38,  2.54it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:38,  2.54it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:38,  2.51it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:47,  2.06it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:43,  2.27it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:34,  2.81it/s]\n",
      "  2%|▏         | 2/100 [00:00<00:36,  2.66it/s]\n",
      "  7%|▋         | 7/100 [00:02<00:28,  3.24it/s]\n",
      " 46%|████▌     | 46/100 [00:10<00:12,  4.45it/s]\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.18it/s]\n",
      "100%|██████████| 100/100 [00:22<00:00,  4.37it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n",
      " 99%|█████████▉| 99/100 [00:28<00:00,  3.44it/s]\n",
      " 64%|██████▍   | 64/100 [00:20<00:11,  3.18it/s]\n",
      " 48%|████▊     | 48/100 [00:16<00:17,  2.89it/s]\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.33it/s]\n",
      " 22%|██▏       | 22/100 [00:06<00:23,  3.26it/s]\n",
      " 17%|█▋        | 17/100 [00:05<00:26,  3.18it/s]\n",
      "100%|██████████| 21/21 [03:22<00:00,  9.65s/it]\n"
     ]
    }
   ],
   "source": [
    "best_alpha,best_betaU,best_betaI,best_lambda,min_mse = None,None,None,None,10000000.0\n",
    "for i in tqdm(range(-10,11)):\n",
    "    regular_lambda = (2**i)\n",
    "    a,bu,bi,mse1 = q8_fit(regular_lambda)\n",
    "    if mse1<min_mse:\n",
    "        best_alpha,best_betaU,best_betaI,best_lambda,min_mse = a,bu,bi,regular_lambda,mse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:14<00:16,  3.26it/s]\n",
      " 53%|█████▎    | 53/100 [00:15<00:13,  3.45it/s]\n",
      " 60%|██████    | 60/100 [00:18<00:12,  3.22it/s]\n",
      " 69%|██████▉   | 69/100 [00:18<00:08,  3.79it/s]\n",
      " 88%|████████▊ | 88/100 [00:23<00:03,  3.72it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.25it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.72it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.87it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.77it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.15it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.17it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "100%|██████████| 100/100 [00:35<00:00,  2.85it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.57it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.83it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.88it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.88it/s]\n",
      "100%|██████████| 20/20 [08:35<00:00, 25.79s/it]\n"
     ]
    }
   ],
   "source": [
    "best_alpha,best_betaU,best_betaI,best_lambda,min_mse = None,None,None,None,10000000.0\n",
    "for i in tqdm(range(20)):\n",
    "    regular_lambda = 2+0.3*i\n",
    "    a,bu,bi,mse1 = q8_fit(regular_lambda)\n",
    "    if mse1<min_mse:\n",
    "        best_alpha,best_betaU,best_betaI,best_lambda,min_mse = a,bu,bi,regular_lambda,mse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.699999999999999, 3.0062019059079907)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lambda,min_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(u,g):\n",
    "    res = best_alpha\n",
    "    if u in betaU:\n",
    "        res+=best_betaU[u]\n",
    "    if g in betaI:\n",
    "        res+=best_betaI[g]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = [best_lambda,min_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(q8_output_path, 'w')\n",
    "for l in open(PAIR_HOUR_TESTSET_FILE_DEFAULT_PATH):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    # Logic...\n",
    "    \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(predict(u,g)) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw3.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
